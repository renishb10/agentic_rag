# Agentic RAG with LangGraph ğŸš€

This project demonstrates an **Agentic RAG (Retrieval-Augmented Generation)** workflow built with **LangGraph**.  
It chains together multiple reasoning nodes (retrieval, grading, planning, answering, etc.) into a **directed graph** where the LLM can decide how to proceed based on intermediate results.

---

## âœ¨ Features

- **LangGraph-based orchestration** of RAG pipeline.
- **Agentic workflow** â€” the LLM reflects and decides next steps instead of a fixed chain.
- **Custom nodes** for:
  - ğŸ” Document retrieval
  - ğŸ“ Answer generation
  - ğŸ› ï¸ Document grading & routing
  - ğŸ§­ Planning and query transformation
- **Extensible** â€” add your own nodes as callable functions.

---

## ğŸ“š RAG Variants

### ğŸ”„ Corrective RAG (CRAG)

CRAG introduces a **grading step** for retrieved documents.  
If documents are irrelevant or low-quality, the retriever is asked to refine and fetch better results before answering.

### ğŸ§  Self-RAG

Self-RAG extends RAG by letting the LLM **reflect on its own answer quality**.  
The model can decide to re-query, add missing context, or improve its response iteratively.

### âš–ï¸ Adaptive RAG

Adaptive RAG dynamically **chooses the best RAG strategy** (basic retrieval, corrective loop, or self-reflection) depending on the query type and context.  
This ensures a balance between efficiency and quality.

---

## ğŸ“‚ Project Structure

```
agentic_rag/
â”‚â”€â”€ graph/
â”‚   â”œâ”€â”€ graph.py            # Builds the workflow graph
â”‚   â”œâ”€â”€ state.py            # Defines shared state schema
â”‚   â””â”€â”€ nodes/              # Node implementations
â”‚       â”œâ”€â”€ retrieve.py
â”‚       â”œâ”€â”€ grade_documents.py
â”‚       â”œâ”€â”€ answer.py
â”‚       â”œâ”€â”€ plan.py
â”‚       â”œâ”€â”€ transform_query.py
â”‚       â”œâ”€â”€ route_documents.py
â”‚       â””â”€â”€ decide_to_generate.py
â”‚â”€â”€ ingestion.py            # Retriever setup (Pinecone / Chroma / etc.)
â”‚â”€â”€ main.py                 # App entrypoint
â”‚â”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup

### 1. Clone the repo

```bash
git clone https://github.com/yourname/agentic_rag.git
cd agentic_rag
```

### 2. Create virtual environment

```bash
python -m venv .venv
source .venv/bin/activate   # macOS/Linux
.venv\Scripts\activate      # Windows
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Environment variables

Create a `.env` file in the project root:

```env
OPENAI_API_KEY=your_api_key
PINECONE_API_KEY=your_pinecone_key
PINECONE_ENV=your_env
USER_AGENT=agentic-rag/0.1
```

---

## â–¶ï¸ Running the App

```bash
python main.py
```

Example output:

```
---RETRIEVE---
---GRADE_DOCUMENTS---
---PLAN---
---ANSWER---
```

The graph executes dynamically based on the conversation state.

---

## ğŸ–‡ï¸ Graph Visualization

LangGraph can render the workflow:

```python
graph.get_graph().draw_mermaid_png("graph.png")
```

### Graph Example:

![Graph](graph.png)

### Output:

![Output](static/output.png)

---

## âœ… Important Notes

- Each node must be a **callable function or Runnable**, not a module.  
  Example:

  ```python
  # Good
  from graph.nodes.retrieve import retrieve
  workflow.add_node("RETRIEVE", retrieve)

  # Bad
  from graph import retrieve   # â† module, causes TypeError
  ```

- Models like `gpt-3.5-turbo` donâ€™t support JSON Schema structured outputs.  
  Use `method="function_calling"` or switch to `gpt-4o-mini`/`gpt-4.1`.

---

## ğŸ”® Next Steps

- Add **Reflexion** loop for self-improvement.
- Plug in **custom retrievers** (e.g., Tavily, Elasticsearch).
- Extend with **tool use** (web search, calculators, APIs).

---

## ğŸ“œ License

MIT License Â© 2025
